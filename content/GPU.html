
<!DOCTYPE html>

<html lang="zh_CN">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>GPU 设备 &#8212; OpenVINO  文档</title>
    
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/blank.css" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    <link rel="stylesheet" type="text/css" href="../_static/doxyrest-pygments.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <link href="../_static/css/media/favicon.ico" rel="shortcut icon">
    <link rel="stylesheet" href="../_static/css/openvino_sphinx_theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/button.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/input.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/textfield.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/tabs.css" type="text/css" />
    <script src="../_static/js/openvino_sphinx_theme.js"></script>
    <link rel="stylesheet" href="../_static/css/viewer.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />

    <script src="https://cdn.jsdelivr.net/npm/chart.js@2.9.3/dist/Chart.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-datalabels"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/chartjs-plugin-annotation/0.5.7/chartjs-plugin-annotation.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-barchart-background@1.3.0/build/Plugin.Barchart.Background.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-deferred@1"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/PapaParse/5.3.1/papaparse.min.js"></script>
    <script src="../_static/js/viewer.min.js"></script>
    <script src="/assets/versions_raw.js"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/tabs.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/translations.js"></script>
    <script src="../_static/target-highlight.js"></script>
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="搜索" href="../search.html" />
    <link rel="next" title="获得性能数据" href="Getting_performance_numbers.html" />
    <link rel="prev" title="推理设备支持" href="Device_Plugins.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="zh_CN">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
      <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    
<a class="navbar-brand" href="../index.html">
<p class="title">OpenVINO</p>
</a>

    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="index.html">
  OpenVINO
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
</ul>
      </div>
      
      <div class="navbar-end-item">
        
<div class="dropdown sst-dropdown sst-dropdown-navbar">
  <button class="btn sst-btn dropdown-toggle" type="button" id="version-selector" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"></button>
  <div class="dropdown-menu" aria-labelledby="version-selector">
  </div>
</div>
      </div>
      
      <div class="navbar-end-item">
        

      </div>
      
    </div>
  </div>
</div>
        <div id="collapse-nav-wrapper" class="container-xl">
          <button id="collapse-nav" class="button bttn-prm button-size-m" type="button" data-toggle="collapse" data-target="#nav-tree" aria-expanded="false" aria-controls="nav-tree">
            Documentation navigation <i class="fas fa-chevron-down"></i>
          </button>
        </div>
      </nav>
      <div class="transition-banner container-fluid alert alert-info alert-dismissible fade show" role="alert">
        <p>OpenVINO 2022.1 introduces a new version of OpenVINO API (API 2.0). For more information on the changes and transition steps, see the <a href="https://docs.openvino.ai/latest/openvino_2_0_transition_guide.html">transition guide</a></p>
        <button type="button" class="close" data-dismiss="alert" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
    </div>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar" id="nav-tree"><form class="searchForm bd-search d-flex align-items-center" action="../search.html" method="get">
    <i class="icon fas fa-search"></i>
    <input type="search" class="form-control" name="query" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="CPU.html">
   CPU 设备
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Convert_Model_From_Paddle.html">
   转换 PadlePaddle 模型
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="Deep_Learning_Model_Optimizer_DevGuide.html">
   模型优化器用法
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="simple">
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="Device_Plugins.html">
   推理设备支持
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="simple">
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="current reference internal" href="#">
   GPU 设备
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="simple">
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Getting_performance_numbers.html">
   获得性能数据
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="Intro.html">
   OpenVINO™ API 2.0 迁移指南
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="simple">
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="OTE_landing_page.html">
   OpenVINO™ 训练扩展
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="README.html">
   模型下载程序和其他自动化工具
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="common_inference_pipeline.html">
   推理管道
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="configure_devices.html">
   配置设备
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="deployment_guide_introduction.html">
   OpenVINO™ 部署简介
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="deployment_intro.html">
   使用 OpenVINO™ 部署应用
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="simple">
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="deployment_migration.html">
   安装和部署
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="dl_workbench_overview.html">
   OpenVINO™ 深度学习工作台概述
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="simple">
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="dldt_deployment_optimization_guide.html">
   运行时推理优化
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="simple">
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="dldt_optimization_guide.html">
   性能优化简介虽然推理性能应定义为许多因素（包括精度和效率）的组合，但多数情况下会将其描述为执行速度。作为模型处理实时数据的速率，从根本上说，它基于两个相互关联的指标：延迟和吞吐量。
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="dlstreamer.html">
   英特尔® Deep Learning Streamer（英特尔® DL Streamer）
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="gapi_intro.html">
   OpenCV Graph API (G-API) 简介
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="simple">
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="graph_construction.html">
   在 OpenVINO™ 运行时创建模型
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="home.html">
   OpenVINO™ 模型服务器
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="simple">
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="introduction.html">
   OpenVINO™ 安全性简介
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="model_introduction.html">
   模型处理简介
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="model_optimization_guide.html">
   模型优化指南
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="simple">
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="openvino_ecosystem.html">
   OpenVINO™ 生态系统概述
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="openvino_ecosystem_ovtf.html">
   OpenVINO™ 与 TensorFlow 集成
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="openvino_intro.html">
   利用 OpenVINO™ 运行时展开推理
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="simple">
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="ov_dynamic_shapes.html">
   动态形状
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="simple">
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="ov_transformations.html">
   转换 API 概述
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="simple">
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ovsa_get_started.html">
   OpenVINO™ 安全附加组件
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="performance_benchmarks.html">
   性能基准测试
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
  <label for="toctree-checkbox-14">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="simple">
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="performance_hints.html">
   高级别性能提示
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="preprocessing.html">
   预处理
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="protecting_model_guide.html">
   结合使用加密模型和 OpenVINO
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="supported_model_formats.html">
   支持的模型格式
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
  <label for="toctree-checkbox-15">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="simple">
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="workbench.html">
   深度学习工作台安全性
  </a>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   设备命名约定
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   支持的推理数据类型
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id3">
   支持的功能
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     多设备执行
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     自动批处理
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id6">
     多流执行
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id7">
     动态输入
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id8">
     预处理加速
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id9">
     模型缓存
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id10">
     扩展性
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#gpu-remotetensor-api">
     GPU 上下文和内存通过 RemoteTensor API 共享
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id11">
   支持的属性
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id12">
     读写属性
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id13">
     只读属性
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id14">
   限制
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gpu-a-name-gpu-checklist-a">
   GPU 性能清单：摘要
   <a name="gpu-checklist">
   </a>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id15">
   其他资源
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                <div class="tocsection download-docs">
  <div class="dropdown sst-dropdown">
    <button class="button bttn-prm button-size-m" data-display="static" type="button" id="download-options"
      data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
      Download Docs
    </button>
    <div class="dropdown-menu" aria-labelledby="download-options">
      <a class="dropdown-item" href="#" onclick="window.print()">.pdf</a>
      <a id="download-zip-btn" class="dropdown-item" href="#">.zip</a>
    </div>
  </div>
</div>
              </div>
              
            
          </div>
          

          
          
              
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
            
                <div>
                  
  <section id="gpu">
<h1>GPU 设备<a class="headerlink" href="#gpu" title="永久链接至标题">¶</a></h1>
<div class="toctree-wrapper compound">
</div>
<p>GPU 插件是一个基于 OpenCL 的插件，用于在英特尔 GPU 上推理深度神经网络，包括集成 GPU 和独立 GPU。
有关 GPU 插件的深入描述，请参见：</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/openvinotoolkit/openvino/wiki/GPUPluginDevelopersDocs">GPU 插件开发人员文档</a></p></li>
<li><p><a class="reference external" href="https://github.com/openvinotoolkit/openvino/tree/master/src/plugins/intel_gpu/">OpenVINO™ 运行时 GPU 插件源文件</a></p></li>
<li><p><a class="reference external" href="https://software.intel.com/en-us/articles/accelerating-deep-learning-inference-with-intel-processor-graphics">通过英特尔® 处理器显卡加速深度学习推理</a>。</p></li>
</ul>
<p>GPU 插件是英特尔® 发行版 OpenVINO™ 工具套件的一部分。有关如何配置系统以便使用它的更多详细信息，请参见 [GPU 配置](&#64;ref openvino_docs_install_guides_configurations_for_intel_gpu)。</p>
<section id="id1">
<h2>设备命名约定<a class="headerlink" href="#id1" title="永久链接至标题">¶</a></h2>
<ul class="simple">
<li><p>设备被枚举为 <code class="docutils literal notranslate"><span class="pre">GPU.X</span></code>。其中 <code class="docutils literal notranslate"><span class="pre">X={0,</span> <span class="pre">1,</span> <span class="pre">2,...}</span></code>（仅考虑英特尔® GPU 设备）。</p></li>
<li><p>如果系统具有集成 GPU，则其 <code class="docutils literal notranslate"><span class="pre">id</span></code> 始终为 0 (<code class="docutils literal notranslate"><span class="pre">GPU.0</span></code>)。</p></li>
<li><p>其他 GPU 的顺序不是预定义的，并且取决于 GPU 驱动程序。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">GPU</span></code> 是 <code class="docutils literal notranslate"><span class="pre">GPU.0</span></code> 的别名。</p></li>
<li><p>如果系统没有集成 GPU，则从 0 开始枚举设备。</p></li>
<li><p>对于具有多块架构的 GPU（用 OpenCL 术语来说指的是多个子设备），特定块可以作为 <code class="docutils literal notranslate"><span class="pre">GPU.X.Y</span></code> 进行寻址。其中 <code class="docutils literal notranslate"><span class="pre">X,Y={0,</span> <span class="pre">1,</span> <span class="pre">2,...}</span></code>，<code class="docutils literal notranslate"><span class="pre">X</span></code> 是 GPU 设备的 ID，<code class="docutils literal notranslate"><span class="pre">Y</span></code> 是设备 <code class="docutils literal notranslate"><span class="pre">X</span></code> 内块的 ID</p></li>
</ul>
<p>为了演示目的，请参见 <span class="xref myst">Hello 查询设备 C++ 样本</span>，使用该样本可以打印出具有关联索引的可用设备列表。下面是一个示例输出（仅截断为设备名称）：</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>./hello_query_device
Available devices:
    Device: CPU
...
    Device: GPU.0
...
    Device: GPU.1
...
    Device: HDDL
</pre></div>
</div>
<p>然后，设备名称可以传递到 <code class="docutils literal notranslate"><span class="pre">ov::Core::compile_model()</span></code> 方法：</p>
<p>&#64;sphinxtabset</p>
<p>&#64;sphinxtab{在默认设备上运行}</p>
<p>&#64;sphinxtabset</p>
<p>&#64;sphinxtab{C++}
&#64;snippet docs/snippets/gpu/compile_model.cpp compile_model_default_gpu
&#64;endsphinxtab</p>
<p>&#64;sphinxtab{Python}
&#64;snippet docs/snippets/gpu/compile_model.py compile_model_default_gpu
&#64;endsphinxtab</p>
<p>&#64;endsphinxtabset</p>
<p>&#64;endsphinxtab</p>
<p>&#64;sphinxtab{在特定 GPU 上运行}</p>
<p>&#64;sphinxtabset</p>
<p>&#64;sphinxtab{C++}
&#64;snippet docs/snippets/gpu/compile_model.cpp compile_model_gpu_with_id
&#64;endsphinxtab</p>
<p>&#64;sphinxtab{Python}
&#64;snippet docs/snippets/gpu/compile_model.py compile_model_gpu_with_id
&#64;endsphinxtab</p>
<p>&#64;endsphinxtabset</p>
<p>&#64;endsphinxtab</p>
<p>&#64;sphinxtab{在特定块上运行}</p>
<p>&#64;sphinxtabset</p>
<p>&#64;sphinxtab{C++}
&#64;snippet docs/snippets/gpu/compile_model.cpp compile_model_gpu_with_id_and_tile
&#64;endsphinxtab</p>
<p>&#64;sphinxtab{Python}
&#64;snippet docs/snippets/gpu/compile_model.py compile_model_gpu_with_id_and_tile
&#64;endsphinxtab</p>
<p>&#64;endsphinxtabset</p>
<p>&#64;endsphinxtab</p>
<p>&#64;endsphinxtabset</p>
</section>
<section id="id2">
<h2>支持的推理数据类型<a class="headerlink" href="#id2" title="永久链接至标题">¶</a></h2>
<p>GPU 插件支持以下数据类型作为内部基元的推理精度：</p>
<ul class="simple">
<li><p>浮点数据类型：</p>
<ul>
<li><p>f32</p></li>
<li><p>f16</p></li>
</ul>
</li>
<li><p>量化数据类型：</p>
<ul>
<li><p>u8</p></li>
<li><p>i8</p></li>
<li><p>u1</p></li>
</ul>
</li>
</ul>
<p>每个基元的所选精度取决于 IR 中的操作精度、量化基元和可用的硬件功能。
<code class="docutils literal notranslate"><span class="pre">u1</span></code>/<code class="docutils literal notranslate"><span class="pre">u8</span></code>/<code class="docutils literal notranslate"><span class="pre">i8</span></code> 数据类型仅用于量化操作，这意味着不会为非量化操作自动选择它们。
有关如何获得量化模型的更多详细信息，请参阅[模型优化指南](&#64;ref openvino_docs_model_optimization_guide)。</p>
<p>GPU 基元的浮点精度是根据 OpenVINO™ IR 中的操作精度选择的，但<span class="xref myst">压缩的 f16 OpenVINO™ IR 格式</span>除外。该格式以 <code class="docutils literal notranslate"><span class="pre">f16</span></code> 精度执行。</p>
<blockquote>
<div><p><strong>注意</strong>：<code class="docutils literal notranslate"><span class="pre">i8</span></code>/<code class="docutils literal notranslate"><span class="pre">u8</span></code> 精度的硬件加速在某些平台上可能不可用。在这种情况下，以从 IR 获取的浮点精度执行模型。可以通过 <code class="docutils literal notranslate"><span class="pre">ov::device::capabilities</span></code> 属性查询支持 <code class="docutils literal notranslate"><span class="pre">u8</span></code>/<code class="docutils literal notranslate"><span class="pre">i8</span></code> 加速的硬件。</p>
</div></blockquote>
<p><span class="xref myst">Hello 查询设备 C++ 样本</span>可以用于打印出所有检测到的设备支持的数据类型。</p>
</section>
<section id="id3">
<h2>支持的功能<a class="headerlink" href="#id3" title="永久链接至标题">¶</a></h2>
<p>GPU 插件支持下列功能：</p>
<section id="id4">
<h3>多设备执行<a class="headerlink" href="#id4" title="永久链接至标题">¶</a></h3>
<p>如果系统具有多个 GPU（例如，集成的英特尔 GPU 和单独的英特尔 GPU），则任何支持的模型都可以同时在所有 GPU 上执行。
通过指定 <code class="docutils literal notranslate"><span class="pre">MULTI:GPU.1,GPU.0</span></code> 为目标设备来完成。</p>
<p>&#64;sphinxtabset</p>
<p>&#64;sphinxtab{C++}
&#64;snippet docs/snippets/gpu/compile_model.cpp compile_model_multi
&#64;endsphinxtab</p>
<p>&#64;sphinxtab{Python}
&#64;snippet docs/snippets/gpu/compile_model.py compile_model_multi
&#64;endsphinxtab</p>
<p>&#64;endsphinxtabset</p>
<p>有关更多详细信息，请参见<span class="xref myst">多设备执行</span>。</p>
</section>
<section id="id5">
<h3>自动批处理<a class="headerlink" href="#id5" title="永久链接至标题">¶</a></h3>
<p>GPU 插件能够报告与当前硬件平台和模型相关的 <code class="docutils literal notranslate"><span class="pre">ov::max_batch_size</span></code> 和 <code class="docutils literal notranslate"><span class="pre">ov::optimal_batch_size</span></code> 指标。因此，当 <code class="docutils literal notranslate"><span class="pre">ov::optimal_batch_size</span></code> 为 <code class="docutils literal notranslate"><span class="pre">&gt;</span> <span class="pre">1</span></code> 且设置 <code class="docutils literal notranslate"><span class="pre">ov::hint::performance_mode(ov::hint::PerformanceMode::THROUGHPUT)</span></code> 时，默认情况下会启用自动批处理。或者，可以通过设备概念明确启用它，例如 <code class="docutils literal notranslate"><span class="pre">BATCH:GPU</span></code>。</p>
<p>&#64;sphinxtabset</p>
<p>&#64;sphinxtab{通过 BATCH 插件进行批处理}</p>
<p>&#64;sphinxtabset</p>
<p>&#64;sphinxtab{C++}
&#64;snippet docs/snippets/gpu/compile_model.cpp compile_model_batch_plugin
&#64;endsphinxtab</p>
<p>&#64;sphinxtab{Python}
&#64;snippet docs/snippets/gpu/compile_model.py compile_model_batch_plugin
&#64;endsphinxtab</p>
<p>&#64;endsphinxtabset</p>
<p>&#64;endsphinxtab</p>
<p>&#64;sphinxtab{通过吞吐量提示进行批处理}</p>
<p>&#64;sphinxtabset</p>
<p>&#64;sphinxtab{C++}
&#64;snippet docs/snippets/gpu/compile_model.cpp compile_model_auto_batch
&#64;endsphinxtab</p>
<p>&#64;sphinxtab{Python}
&#64;snippet docs/snippets/gpu/compile_model.py compile_model_auto_batch
&#64;endsphinxtab</p>
<p>&#64;endsphinxtabset</p>
<p>&#64;endsphinxtab</p>
<p>&#64;endsphinxtabset</p>
<p>有关更多详细信息，请参见<span class="xref myst">自动批处理</span>。</p>
</section>
<section id="id6">
<h3>多流执行<a class="headerlink" href="#id6" title="永久链接至标题">¶</a></h3>
<p>如果为 GPU 插件设置 <code class="docutils literal notranslate"><span class="pre">ov::num_streams(n_streams)</span></code> (<code class="docutils literal notranslate"><span class="pre">n_streams</span> <span class="pre">&gt;</span> <span class="pre">1</span></code>) 或 <code class="docutils literal notranslate"><span class="pre">ov::hint::performance_mode(ov::hint::PerformanceMode::THROUGHPUT)</span></code> 属性，则可以为模型创建多个流。如果是 CPU 插件，每个流都有自己的主机线程和相关的 OpenCL 队列，这意味着可以同时处理传入的推理请求。</p>
<blockquote>
<div><p><strong>注意</strong>：将内核同时调度到不同的队列并不意味着内核实际上是在 GPU 设备上并行执行的。实际行为取决于硬件架构，并且在某些情况下，执行可能会在 GPU 驱动程序中序列化。</p>
</div></blockquote>
<p>当需要并行执行同一模型的多个推理时，多流功能优先于模型或应用的多个实例。
其原因是 GPU 插件中的流实现支持所有流中共享权重内存。因此，与其他方法相比，内存消耗可能更低。</p>
<p>有关更多详细信息，请参见[优化指南](&#64;ref openvino_docs_deployment_optimization_guide_dldt_optimization_guide)。</p>
</section>
<section id="id7">
<h3>动态输入<a class="headerlink" href="#id7" title="永久链接至标题">¶</a></h3>
<p>GPU 插件仅支持具有固定上限的批处理维度的动态形状（在<span class="xref myst">布局术语</span>中指定为 <code class="docutils literal notranslate"><span class="pre">N</span></code>）。不支持任何其他动态维度。在内部，GPU 插件为等于 2 的幂数的批次大小创建 <code class="docutils literal notranslate"><span class="pre">log2(N)</span></code>（<code class="docutils literal notranslate"><span class="pre">N</span></code> - 此处是批处理维度的上限）低级执行图来模拟动态行为，以便通过内部网络的最小组合来执行具有特定批次大小的传入推理请求。
例如，可以通过批次大小为 32 和 1 的 2 个内部网络执行批次大小 33。</p>
<blockquote>
<div><p><strong>注意</strong>：与静态批处理场景相比，这种方法需要更多内存，并且整个模型的编译时间明显更长。</p>
</div></blockquote>
<p>以下代码片段演示了如何在简单场景中使用动态批处理：</p>
<p>&#64;sphinxtabset</p>
<p>&#64;sphinxtab{C++}
&#64;snippet docs/snippets/gpu/dynamic_batch.cpp dynamic_batch
&#64;endsphinxtab</p>
<p>&#64;sphinxtab{Python}
&#64;snippet docs/snippets/gpu/dynamic_batch.py dynamic_batch
&#64;endsphinxtab</p>
<p>&#64;endsphinxtabset</p>
<p>有关更多详细信息，请参见<span class="xref myst">动态形状指南</span>。</p>
</section>
<section id="id8">
<h3>预处理加速<a class="headerlink" href="#id8" title="永久链接至标题">¶</a></h3>
<p>GPU 插件具有以下附加预处理选项：</p>
<ul class="simple">
<li><p>用于 <code class="docutils literal notranslate"><span class="pre">ov::preprocess::InputTensorInfo::set_memory_type()</span></code> 预处理方法的 <code class="docutils literal notranslate"><span class="pre">ov::intel_gpu::memory_type::surface</span></code> 和 <code class="docutils literal notranslate"><span class="pre">ov::intel_gpu::memory_type::buffer</span></code> 值。这些值旨在用于为插件提供输入张量类型相关的提示，这些张量将在运行时设置，以生成适当的内核。</p></li>
</ul>
<p>&#64;sphinxtabset</p>
<p>&#64;sphinxtab{C++}
&#64;snippet docs/snippets/gpu/preprocessing.cpp init_preproc
&#64;endsphinxtab</p>
<p>&#64;sphinxtab{Python}
&#64;snippet docs/snippets/gpu/preprocessing.py init_preproc
&#64;endsphinxtab</p>
<p>&#64;endsphinxtabset</p>
<p>通过这种预处理，GPU 插件将期望通过 <code class="docutils literal notranslate"><span class="pre">ov::InferRequest::set_tensor()</span></code> 或 <code class="docutils literal notranslate"><span class="pre">ov::InferRequest::set_tensors()</span></code> 方法为每个 NV12 平面传递 <code class="docutils literal notranslate"><span class="pre">ov::intel_gpu::ocl::ClImage2DTensor</span></code>（或派生）。</p>
<p>有关使用示例，请参阅 <span class="xref myst">RemoteTensor API</span>。</p>
<p>有关更多详细信息，请参见<span class="xref myst">预处理 API</span>。</p>
</section>
<section id="id9">
<h3>模型缓存<a class="headerlink" href="#id9" title="永久链接至标题">¶</a></h3>
<p>可以通过通用 OpenVINO™ <code class="docutils literal notranslate"><span class="pre">ov::cache_dir</span></code> 属性启用 GPU 插件的缓存。GPU 插件实现仅支持缓存已编译内核。因此无论 <code class="docutils literal notranslate"><span class="pre">cache_dir</span></code> 选项如何，所有插件特定的模型转换都会在每个 <code class="docutils literal notranslate"><span class="pre">ov::Core::compile_model()</span></code> 调用时执行。
尽管如此，由于内核编译是模型加载过程中的瓶颈。因此启用 <code class="docutils literal notranslate"><span class="pre">ov::cache_dir</span></code> 属性可以显著减少加载时间。</p>
<p>有关更多详细信息，请参见<span class="xref myst">模型缓存概述</span>。</p>
</section>
<section id="id10">
<h3>扩展性<a class="headerlink" href="#id10" title="永久链接至标题">¶</a></h3>
<p>有关此主题的信息，请参见 [GPU 扩展性](&#64;ref openvino_docs_Extensibility_UG_GPU).</p>
</section>
<section id="gpu-remotetensor-api">
<h3>GPU 上下文和内存通过 RemoteTensor API 共享<a class="headerlink" href="#gpu-remotetensor-api" title="永久链接至标题">¶</a></h3>
<p>有关此主题的信息，请参见 <span class="xref myst">GPU 插件的 RemoteTensor API</span>。</p>
</section>
</section>
<section id="id11">
<h2>支持的属性<a class="headerlink" href="#id11" title="永久链接至标题">¶</a></h2>
<p>插件支持以下所列属性。</p>
<section id="id12">
<h3>读写属性<a class="headerlink" href="#id12" title="永久链接至标题">¶</a></h3>
<p>在调用 <code class="docutils literal notranslate"><span class="pre">ov::Core::compile_model()</span></code> 之前必须设置所有参数才能生效或作为附加参数传递给 <code class="docutils literal notranslate"><span class="pre">ov::Core::compile_model()</span></code>。</p>
<ul class="simple">
<li><p>ov::cache_dir</p></li>
<li><p>ov::enable_profiling</p></li>
<li><p>ov::hint::model_priority</p></li>
<li><p>ov::hint::performance_mode</p></li>
<li><p>ov::hint::num_requests</p></li>
<li><p>ov::hint::inference_precision</p></li>
<li><p>ov::num_streams</p></li>
<li><p>ov::compilation_num_threads</p></li>
<li><p>ov::device::id</p></li>
<li><p>ov::intel_gpu::hint::host_task_priority</p></li>
<li><p>ov::intel_gpu::hint::queue_priority</p></li>
<li><p>ov::intel_gpu::hint::queue_throttle</p></li>
<li><p>ov::intel_gpu::enable_loop_unrolling</p></li>
</ul>
</section>
<section id="id13">
<h3>只读属性<a class="headerlink" href="#id13" title="永久链接至标题">¶</a></h3>
<ul class="simple">
<li><p>ov::supported_properties</p></li>
<li><p>ov::available_devices</p></li>
<li><p>ov::range_for_async_infer_requests</p></li>
<li><p>ov::range_for_streams</p></li>
<li><p>ov::optimal_batch_size</p></li>
<li><p>ov::max_batch_size</p></li>
<li><p>ov::device::full_name</p></li>
<li><p>ov::device::type</p></li>
<li><p>ov::device::gops</p></li>
<li><p>ov::device::capabilities</p></li>
<li><p>ov::intel_gpu::device_total_mem_size</p></li>
<li><p>ov::intel_gpu::uarch_version</p></li>
<li><p>ov::intel_gpu::execution_units_count</p></li>
<li><p>ov::intel_gpu::memory_statistics</p></li>
</ul>
</section>
</section>
<section id="id14">
<h2>限制<a class="headerlink" href="#id14" title="永久链接至标题">¶</a></h2>
<p>在某些情况下，GPU 插件可能会使用内部实现在 CPU 上隐式地执行多个基元，这可能会导致 CPU 利用率增加。
以下是此类操作的列表：</p>
<ul class="simple">
<li><p>提案</p></li>
<li><p>NonMaxSuppression</p></li>
<li><p>DetectionOutput</p></li>
</ul>
<p>行为取决于操作的特定参数和硬件配置。</p>
</section>
<section id="gpu-a-name-gpu-checklist-a">
<h2>GPU 性能清单：摘要<a name="gpu-checklist"></a><a class="headerlink" href="#gpu-a-name-gpu-checklist-a" title="永久链接至标题">¶</a></h2>
<p>由于 OpenVINO™ 依赖 OpenCL 内核进行 GPU 实现。因此许多通用 OpenCL 提示都适用：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">FP16</span></code> 推理精度优于 <code class="docutils literal notranslate"><span class="pre">FP32</span></code>，因为模型优化器可以生成两个变体，并且 <code class="docutils literal notranslate"><span class="pre">FP32</span></code> 是默认值。此外，请考虑使用<a class="reference external" href="https://docs.openvino.ai/latest/pot_introduction.html">训练后优化工具</a>。</p></li>
<li><p>尝试使用<span class="xref myst">自动批处理</span>对各个推理作业进行分组。</p></li>
<li><p>考虑<span class="xref myst">缓存</span>，以尽量减少模型加载时间。</p></li>
<li><p>如果您的应用在 CPU 和 GPU 上执行推理，或者以其他方式重载主机，请确保 OpenCL 驱动程序线程不会停顿。<a class="reference internal" href="CPU.html"><span class="doc std std-doc">CPU 配置选项</span></a>可以用于限制 CPU 插件的推理线程数量。</p></li>
<li><p>即使仅在 GPU 上执行推理，GPU 驱动程序可能会占用 CPU 核心，并通过自旋循环轮询来完成。如果 CPU 负载是一个问题，请考虑前面提到的专用 <code class="docutils literal notranslate"><span class="pre">queue_throttle</span></code> 属性。请注意，此选项可能会增加推理延迟。因此请考虑将其与多个 GPU 流或<span class="xref myst">吞吐量性能提示</span>结合使用。</p></li>
<li><p>操作媒体输入时，请考虑 <span class="xref myst">GPU 插件的远程张量 API</span>。</p></li>
</ul>
</section>
<section id="id15">
<h2>其他资源<a class="headerlink" href="#id15" title="永久链接至标题">¶</a></h2>
<ul class="simple">
<li><p><span class="xref myst">支持的设备</span></p></li>
<li><p>[优化指南](&#64;ref openvino_docs_optimization_guide_dldt_optimization_guide)</p></li>
<li><p><a class="reference external" href="https://github.com/openvinotoolkit/openvino/wiki/GPUPluginDevelopersDocs">GPU 插件开发人员文档</a></p></li>
</ul>
</section>
</section>


                </div>
            
            
                <div class='prev-next-bottom'>
                  
    <a class='button bttn-sec button-size-l' id="prev-link" href="Device_Plugins.html" title="previous page">Prev</a>
    <a class='button bttn-sec button-size-l' id="next-link" href="Getting_performance_numbers.html" title="next page">Next</a>

                </div>
            
          </main>
          

      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2022, Various.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.2.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>