
<!DOCTYPE html>

<html lang="zh_CN">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>模型下载程序和其他自动化工具 &#8212; OpenVINO  文档</title>
    
    
  <link href="_static/css/theme.css" rel="stylesheet">
  <link href="_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/css/blank.css" />
    <link rel="stylesheet" type="text/css" href="_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    <link rel="stylesheet" type="text/css" href="_static/doxyrest-pygments.css" />
    
  <link rel="preload" as="script" href="_static/js/index.be7d3bbb2ef33a8344ce.js">

    <link href="_static/css/media/favicon.ico" rel="shortcut icon">
    <link rel="stylesheet" href="_static/css/openvino_sphinx_theme.css" type="text/css" />
    <link rel="stylesheet" href="_static/css/button.css" type="text/css" />
    <link rel="stylesheet" href="_static/css/input.css" type="text/css" />
    <link rel="stylesheet" href="_static/css/textfield.css" type="text/css" />
    <link rel="stylesheet" href="_static/css/tabs.css" type="text/css" />
    <script src="_static/js/openvino_sphinx_theme.js"></script>
    <link rel="stylesheet" href="_static/css/viewer.min.css" type="text/css" />
    <link rel="stylesheet" href="_static/css/custom.css" type="text/css" />

    <script src="https://cdn.jsdelivr.net/npm/chart.js@2.9.3/dist/Chart.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-datalabels"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/chartjs-plugin-annotation/0.5.7/chartjs-plugin-annotation.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-barchart-background@1.3.0/build/Plugin.Barchart.Background.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-deferred@1"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/PapaParse/5.3.1/papaparse.min.js"></script>
    <script src="_static/js/viewer.min.js"></script>
    <script src="/assets/versions_raw.js"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/tabs.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/translations.js"></script>
    <script src="_static/target-highlight.js"></script>
    <link rel="index" title="索引" href="genindex.html" />
    <link rel="search" title="搜索" href="search.html" />
    <link rel="next" title="推理管道" href="common_inference_pipeline.html" />
    <link rel="prev" title="OpenVINO™ 训练扩展" href="OTE_landing_page.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="zh_CN">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
      <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    
<a class="navbar-brand" href="index.html">
<p class="title">OpenVINO</p>
</a>

    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="CPU.html">
  CPU 设备
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="Convert_Model_From_Paddle.html">
  转换 PadlePaddle 模型
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="Deep_Learning_Model_Optimizer_DevGuide.html">
  模型优化器用法
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="Device_Plugins.html">
  推理设备支持
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="GPU.html">
  GPU 设备
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="Getting_performance_numbers.html">
  获得性能数据
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="Intro.html">
  OpenVINO™ API 2.0 迁移指南
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="OTE_landing_page.html">
  OpenVINO™ 训练扩展
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="current reference internal nav-link" href="#">
  模型下载程序和其他自动化工具
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="common_inference_pipeline.html">
  推理管道
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="configure_devices.html">
  配置设备
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="deployment_guide_introduction.html">
  OpenVINO™ 部署简介
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="deployment_intro.html">
  使用 OpenVINO™ 部署应用
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="deployment_migration.html">
  安装和部署
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="dl_workbench_overview.html">
  OpenVINO™ 深度学习工作台概述
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="dldt_deployment_optimization_guide.html">
  运行时推理优化
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="dldt_optimization_guide.html">
  性能优化简介虽然推理性能应定义为许多因素（包括精度和效率）的组合，但多数情况下会将其描述为执行速度。作为模型处理实时数据的速率，从根本上说，它基于两个相互关联的指标：延迟和吞吐量。
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="dlstreamer.html">
  英特尔® Deep Learning Streamer（英特尔® DL Streamer）
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="gapi_intro.html">
  OpenCV Graph API (G-API) 简介
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="graph_construction.html">
  在 OpenVINO™ 运行时创建模型
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="home.html">
  OpenVINO™ 模型服务器
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="introduction.html">
  OpenVINO™ 安全性简介
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="model_introduction.html">
  模型处理简介
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="model_optimization_guide.html">
  模型优化指南
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="openvino_ecosystem.html">
  OpenVINO™ 生态系统概述
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="openvino_ecosystem_ovtf.html">
  OpenVINO™ 与 TensorFlow 集成
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="openvino_intro.html">
  利用 OpenVINO™ 运行时展开推理
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="ov_dynamic_shapes.html">
  动态形状
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="ov_transformations.html">
  转换 API 概述
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="ovsa_get_started.html">
  OpenVINO™ 安全附加组件
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="performance_benchmarks.html">
  性能基准测试
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="performance_hints.html">
  高级别性能提示
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="preprocessing.html">
  预处理
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="protecting_model_guide.html">
  结合使用加密模型和 OpenVINO
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="supported_model_formats.html">
  支持的模型格式
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="workbench.html">
  深度学习工作台安全性
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
</ul>
      </div>
      
      <div class="navbar-end-item">
        
<div class="dropdown sst-dropdown sst-dropdown-navbar">
  <button class="btn sst-btn dropdown-toggle" type="button" id="version-selector" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"></button>
  <div class="dropdown-menu" aria-labelledby="version-selector">
  </div>
</div>
      </div>
      
      <div class="navbar-end-item">
        

      </div>
      
    </div>
  </div>
</div>
        <div id="collapse-nav-wrapper" class="container-xl">
          <button id="collapse-nav" class="button bttn-prm button-size-m" type="button" data-toggle="collapse" data-target="#nav-tree" aria-expanded="false" aria-controls="nav-tree">
            Documentation navigation <i class="fas fa-chevron-down"></i>
          </button>
        </div>
      </nav>
      <div class="transition-banner container-fluid alert alert-info alert-dismissible fade show" role="alert">
        <p>OpenVINO 2022.1 introduces a new version of OpenVINO API (API 2.0). For more information on the changes and transition steps, see the <a href="https://docs.openvino.ai/latest/openvino_2_0_transition_guide.html">transition guide</a></p>
        <button type="button" class="close" data-dismiss="alert" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
    </div>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar" id="nav-tree"><form class="searchForm bd-search d-flex align-items-center" action="search.html" method="get">
    <i class="icon fas fa-search"></i>
    <input type="search" class="form-control" name="query" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    
  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   安装
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id3">
   模型下载程序用法
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     模型下载程序起始参数
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#json">
     JSON 进程报告格式
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id5">
   模型转换器用法
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id6">
     模型转换器起始参数
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id7">
   模型量化器使用
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id8">
   模型信息转储器用法
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id9">
   共享选项
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id10">
   数据集的数据下载程序用法
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                <div class="tocsection download-docs">
  <div class="dropdown sst-dropdown">
    <button class="button bttn-prm button-size-m" data-display="static" type="button" id="download-options"
      data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
      Download Docs
    </button>
    <div class="dropdown-menu" aria-labelledby="download-options">
      <a class="dropdown-item" href="#" onclick="window.print()">.pdf</a>
      <a id="download-zip-btn" class="dropdown-item" href="#">.zip</a>
    </div>
  </div>
</div>
              </div>
              
            
          </div>
          

          
          
              
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
            
                <div>
                  
  <section id="id1">
<h1>模型下载程序和其他自动化工具<a class="headerlink" href="#id1" title="永久链接至标题">¶</a></h1>
<p>Open Model Zoo 自动化工具包含脚本，可根据模型目录中的配置文件自动执行某些模型相关任务。</p>
<ul class="simple">
<li><p>模型下载程序：<code class="docutils literal notranslate"><span class="pre">omz_downloader</span></code> 从在线来源下载模型文件，并在必要时进行修补以使其更适用于模型优化器；</p></li>
<li><p>模型转换器：<code class="docutils literal notranslate"><span class="pre">omz_converter</span></code> 使用模型优化器将不属于 OpenVINO™ IR 格式的模型转换为该格式。</p></li>
<li><p>模型量化器：<code class="docutils literal notranslate"><span class="pre">omz_quantizer</span></code> 使用训练后优化工具套件，将 IR 格式的全精度模型量化为低精度版本。</p></li>
<li><p>模型信息转储器：<code class="docutils literal notranslate"><span class="pre">omz_info_dumper</span></code> 以稳定的机器可读格式打印有关模型的信息。</p></li>
<li><p>数据集的数据下载程序：<code class="docutils literal notranslate"><span class="pre">omz_data_downloader</span></code> 从安装位置复制数据集的数据。</p></li>
</ul>
<p>请使用这些工具而不是尝试直接解析配置文件。它们的格式没有记录，并且可能会在未来版本中以不兼容的方式更改。</p>
<blockquote>
<div><p><strong>提示</strong>：您还可以使用 OpenVINO™ [深度学习工作台](&#64;ref workbench_docs_Workbench_DG_Introduction)中的模型下载程序。
[深度学习工作台](&#64;ref workbench_docs_Workbench_DG_Introduction)是一个基于 OpenVINO™ 构建的平台，它提供基于 Web 的图形环境，可帮助您对深度学习模型在各种英特尔® 架构配置上的性能进行优化、调优、分析、可视化和比较。在深度学习工作台中，您可以使用大多数 OpenVINO™ 工具套件组件。
<br>
继续[从 Docker 轻松安装](&#64;ref workbench_docs_Workbench_DG_Run_Locally)以开始。</p>
</div></blockquote>
<section id="id2">
<h2>安装<a class="headerlink" href="#id2" title="永久链接至标题">¶</a></h2>
<p>模型下载程序和其他自动化工具可以作为 OpenVINO™ 开发工具 Python 程序包的一部分进行安装，或在需要最新更改时从相关来源进行安装。
如需安装程序包中的工具，请访问 [OpenVINO™ 开发工具 PyPI 页面] (https://pypi.org/project/openvino-dev/) 并按照说明操作。</p>
<p>如需从相关来源安装工具：</p>
<ol class="arabic simple">
<li><p>安装 Python（版本 3.6 或更高版本），<a class="reference external" href="https://pypi.org/project/setuptools/">安装工具</a>：</p></li>
<li><p>安装 <a class="reference external" href="https://pypi.org/project/openvino-dev/">openvino-dev</a> Python* 程序包以获取模型优化器和训练后优化工具套件：</p></li>
</ol>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>pip install openvino-dev
</pre></div>
</div>
<blockquote>
<div><p><strong>注意</strong>：openvino-dev 的版本应与 OMZ 工具相同。例如，如果正使用 2021.4.2 版本的 OMZ 工具，则安装 openvino-dev==2021.4.2。</p>
</div></blockquote>
<ol class="arabic simple" start="2">
<li><p>使用以下命令安装工具：</p></li>
</ol>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>pip install --upgrade pip
pip install .
</pre></div>
</div>
<blockquote>
<div><p><strong>注意</strong>：在 Linux 和 macOS 上，您可能需要键入 <code class="docutils literal notranslate"><span class="pre">python3</span></code> 而不是 <code class="docutils literal notranslate"><span class="pre">python</span></code>。可能还需要<a class="reference external" href="https://pip.pypa.io/en/stable/installation/">安装 pip</a>。
例如，在 Ubuntu 上，请执行以下命令以安装 pip：<code class="docutils literal notranslate"><span class="pre">sudo</span> <span class="pre">apt</span> <span class="pre">install</span> <span class="pre">python3-pip</span></code>。
如果使用的 pip 版本低于 21.3，还需要设置 OMZ_ROOT 变量：<code class="docutils literal notranslate"><span class="pre">export</span> <span class="pre">OMZ_ROOT=&lt;omz_dir&gt;</span></code></p>
</div></blockquote>
<p>如需从某些框架转换模型，可能还需要安装其他依赖项。</p>
<!--
```{eval-rst}

.. tab:: PyTorch
    
      .. code-block:: sh
    
        python -mpip install --user -r ./requirements-pytorch.in
    
.. tab:: TensorFlow
    
      .. code-block:: sh
    
        python -mpip install --user -r ./requirements-tensorflow.in
    
.. tab:: PaddlePaddle
    
      .. code-block:: sh
    
        python -mpip install --user -r ./requirements-paddle.in
    
```-->
</section>
<section id="id3">
<h2>模型下载程序用法<a class="headerlink" href="#id3" title="永久链接至标题">¶</a></h2>
<p>基本用法是像以下方式运行脚本：</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>omz_downloader --all
</pre></div>
</div>
<p>这将下载所有模型。<code class="docutils literal notranslate"><span class="pre">--all</span></code> 选项可以用其他筛选选项替代，以仅下载一小部分模型。请参阅“共享选项”部分。</p>
<section id="id4">
<h3>模型下载程序起始参数<a class="headerlink" href="#id4" title="永久链接至标题">¶</a></h3>
<!--
```{eval-rst}

+---------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------+
| Parameter                 | Explanation                                                                                                                                                                                                                                                                                                                                                                                      | Example                                                                             |
+===========================+==================================================================================================================================================================================================================================================================================================================================================================================================+=====================================================================================+
| ``-o``/``--output_dir``   | By default, the script will download models into a directory tree rooted in the current directory. Use this parameter to download into a different directory.                                                                                                                                                                                                                                    | ``omz_downloader --all --output_dir my/download/directory``                        |
+---------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------+
| ``--precisions``          | Specify comma separated precisions of weights to be downloaded                                                                                                                                                                                                                                                                                                                                   | ``omz_downloader --name face-detection-retail-0004 --precisions FP16,FP16-INT8``   |
+---------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------+
| ``--num_attempts``        | By default, the script will attempt to download each file only once. Use this parameter to change that and increase the robustness of the download process                                                                                                                                                                                                                                       | ``omz_downloader --all --num_attempts 5 # attempt each download five times``       |
+---------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------+
| ``--cache_dir``           | Make the script use the specified directory as a cache. The script will place a copy of each downloaded file in the cache, or, if it is already there, retrieve it from the cache instead of downloading it again. The cache format is intended to remain compatible in future Open Model Zoo versions, so you can use a cache to avoid redownloading most files when updating Open Model Zoo.   | ``omz_downloader --all --cache_dir my/cache/directory``                            |
+---------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------+
| ``-j``/``--jobs``         | The script downloads files for multiple models concurrently.                                                                                                                                                                                                                                                                                                                                     | ``omz_downloader --all -j8 # download up to 8 models at a time``                   |
+---------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------+
| ``--progress_format``     | By default, the script outputs progress information as unstructured, human-readable text. You can also set this option to `text` to explicitly request the default text format. When this option is set to `json`, the script's standard output is replaced by a machine-readable progress report, whose format is documented in the "JSON progress report format" section. This option does not affect errors and warnings, which will still be printed to the standard error stream in a human-readable format. Use this option, if you want to consume progress information programmatically.                                                                                                                                                                                                                         | ``omz_downloader --all --progress_format=json``                                    |
+---------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------+
```-->
<p>有关脚本接受的其他选项的信息，请参阅“共享选项”部分。</p>
</section>
<section id="json">
<h3>JSON 进程报告格式<a class="headerlink" href="#json" title="永久链接至标题">¶</a></h3>
<p>本节记录了在指定了 <code class="docutils literal notranslate"><span class="pre">--progress_format=json</span></code> 选项的情况下，脚本生成的进度报告的格式。</p>
<p>该报告由一系列事件组成。其中每个事件由包含 JSON 编码对象的一行表示。每个事件都有一个名为 <code class="docutils literal notranslate"><span class="pre">$type</span></code> 的成员，其值决定事件的类型，以及其包含的其他成员。</p>
<p>当前定义了以下事件类型：</p>
<!--
```{eval-rst}

+------------------------------------+-------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Event type                         | Additional members                                                      | Explanation                                                                                                                                                                                                                                                                                                                                    |
+====================================+=========================================================================+================================================================================================================================================================================================================================================================================================================================================+
| ``model_download_begin``           | ``model`` (string), ``num_files`` (integer)                             | The script started downloading the model named by ``model``. ``num_files`` is the number of files that will be downloaded for this model. This event will always be followed by a corresponding ``model_download_end`` event.                                                                                                                  |
+------------------------------------+-------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| ``model_download_end``             | ``model`` (string), ``successful`` (boolean)                            | The script stopped downloading the model named by ``model``. ``successful`` is true if every file was downloaded successfully.                                                                                                                                                                                                                 |
+------------------------------------+-------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| ``model_file_download_begin``      | ``model`` (string), ``model_file`` (string), ``size`` (integer)         | The script started downloading the file named by ``model_file`` of the model named by ``model``. ``size`` is the size of the file in bytes. This event will always occur between ``model_download_begin`` and ``model_download_end`` events for the model, and will always be followed by a corresponding ``model_file_download_end`` event.   |
+------------------------------------+-------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| ``model_file_download_end``        | ``model`` (string), ``model_file`` (string), ``successful`` (boolean)   | The script stopped downloading the file named by ``model_file`` of the model named by ``model``. ``successful`` is true if the file was downloaded successfully.                                                                                                                                                                               |
+------------------------------------+-------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| ``model_file_download_progress``   | ``model`` (string), ``model_file`` (string), ``size`` (integer)         | The script downloaded ``size`` bytes of the file named by ``model_file`` of the model named by ``model`` so far. Note that ``size`` can decrease in a subsequent event if the download is interrupted and retried. This event will always occur between ``model_file_download_begin`` and ``model_file_download_end`` events for the file.     |
+------------------------------------+-------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| ``model_postprocessing_begin``     | ``model``                                                               | The script started post-download processing on the model named by ``model``. This event will always be followed by a corresponding ``model_postprocessing_end`` event.                                                                                                                                                                         |
+------------------------------------+-------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| ``model_postprocessing_end``       | ``model``                                                               | The script stopped post-download processing on the model named by ``model``.                                                                                                                                                                                                                                                                   |
+------------------------------------+-------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
```-->
<p>将来可能会添加其他事件类型和成员。</p>
<p>解析机器可读格式的工具应避免依赖未记录的细节。
特别是：</p>
<ul class="simple">
<li><p>工具不应该假设任何给定的事件都会发生在给定的模型/文件（除非上面另有说明）或只会发生一次。</p></li>
<li><p>工具不应假设事件会以超出上面指定的顺序约束的特定顺序发生。特别是，如果将 <code class="docutils literal notranslate"><span class="pre">--jobs</span></code> 选项设置为大于 1 的值，不同文件或模型的事件序列可能会交错。</p></li>
</ul>
</section>
</section>
<section id="id5">
<h2>模型转换器用法<a class="headerlink" href="#id5" title="永久链接至标题">¶</a></h2>
<p>基本用法是像以下方式运行脚本：</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>omz_converter --all
</pre></div>
</div>
<p>这会将所有模型转换为 OpenVINO™ IR 格式。最初采用该格式的模型将被忽略。PyTorch 格式的模型首先会转换为 ONNX 格式。</p>
<p><code class="docutils literal notranslate"><span class="pre">--all</span></code> 选项可以用其他筛选选项替代，以仅转换一小部分模型。请参阅“共享选项”部分。</p>
<section id="id6">
<h3>模型转换器起始参数<a class="headerlink" href="#id6" title="永久链接至标题">¶</a></h3>
<!--
```{eval-rst}

+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------+
| Parameter                   | Explanation                                                                                                                                                                                                                                                      | Example                                                                                          |
+=============================+==================================================================================================================================================================================================================================================================+==================================================================================================+
| ``-d``/``--download_dir``   | The current directory must be the root of a download tree created by the model downloader. Use this parameter to specify a different download tree path.                                                                                                         | ``omz_converter --all --download_dir my/download/directory``                                    |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------+
| ``-o``/``--output_dir``     | By default, the script will download models into a directory tree rooted in the current directory. Use this parameter to download into a different directory. Note: models in intermediate format are placed to this directory too.                              | ``omz_converter --all --output_dir my/output/directory``                                        |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------+
| ``--precisions``            | By default, the script will produce models in every precision that is supported for conversion. Use this parameter to only produce models in a specific precision. If the specified precision is not supported for a model, that model will be skipped.          | ``omz_converter --all --precisions=FP16``                                                       |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------+
| ``--add_mo_arg``            | Add extra Model Optimizer arguments to the ones specified in the model configuration. The option can be repeated to add multiple arguments                                                                                                                       | ``omz_converter --name=caffenet --add_mo_arg=--reverse_input_channels --add_mo_arg=--silent``   |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------+
| ``-j``/``--jobs``           | Run multiple conversion commands concurrently. The argument to the option must be either a maximum number of concurrently executed commands, or "auto", in which case the number of CPUs in the system is used. By default, all commands are run sequentially.   | ``omz_converter --all -j8 # run up to 8 commands at a time``                                    |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------+
| ``--dry_run``               | Print the conversion commands without actually running them..                                                                                                                                                                                                    | ``omz_converter --all --dry_run``                                                               |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------+
| ``-p``/``--python``         | By default, the script will run Model Optimizer using the same Python executable that was used to run the script itself. Apply this parameter to use a different Python executable.                                                                              | ``omz_converter --all --python my/python``                                                      |
+-----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------+
```-->
<p>该脚本将尝试使用多种方法找到模型优化器：</p>
<ol class="arabic">
<li><p>如果指定了 <code class="docutils literal notranslate"><span class="pre">--mo</span></code> 选项，那么它的值将被用作要运行的脚本的路径：</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>omz_converter --all --mo my/openvino/path/model_optimizer/mo.py
</pre></div>
</div>
</li>
<li><p>否则，如果选定的 Python 可执行文件可以找到 <code class="docutils literal notranslate"><span class="pre">mo</span></code> 切入点，则会使用该切入点。</p></li>
<li><p>否则，如果已执行 OpenVINO™ 工具套件的 <code class="docutils literal notranslate"><span class="pre">setupvars.sh</span></code>/<code class="docutils literal notranslate"><span class="pre">setupvars.bat</span></code> 脚本，则会将该脚本设置的环境变量用于在工具套件内查找模型优化器。</p></li>
<li><p>否则，脚本将失败。</p></li>
</ol>
</section>
</section>
<section id="id7">
<h2>模型量化器使用<a class="headerlink" href="#id7" title="永久链接至标题">¶</a></h2>
<p>在运行模型量化器之前，您必须准备一个包含量化过程所需数据集的目录。在下文中，此目录将被称为 <code class="docutils literal notranslate"><span class="pre">&lt;DATASET_DIR&gt;</span></code>。您可以在<span class="xref myst">数据集准备指南</span>中找到关于数据集准备的更多详细信息。</p>
<p>基本用法是像以下方式运行脚本：</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>omz_quantizer --all --dataset_dir &lt;DATASET_DIR&gt;
</pre></div>
</div>
<p>这将量化所有支持量化的模型。其他模型被忽略。</p>
<p><code class="docutils literal notranslate"><span class="pre">--all</span></code> 选项可以用其他筛选选项替代，以仅量化一小部分模型。请参阅“共享选项”部分。</p>
<!--
```{eval-rst}

+---------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------+
| Parameter                 | Explanation                                                                                                                                                                                                                                                                                                         | Example                                                                                 |
+===========================+=====================================================================================================================================================================================================================================================================================================================+=========================================================================================+
| ``--model_dir``           | The current directory must be the root of a tree of model files create by the model converter. Use this parameter to specify a different model tree path                                                                                                                                                            | ``omz_quantizer --all --dataset_dir <DATASET_DIR> --model_dir my/model/directory``     |
+---------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------+
| ``-o``/``--output_dir``   | By default, the script will download models into a directory tree rooted in the current directory. Use this parameter to download into a different directory. Note: models in intermediate format are placed to this directory too.                                                                                 | ``omz_quantizer --all --dataset_dir <DATASET_DIR> --output_dir my/output/directory``   |
+---------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------+
| ``--precisions``          | By default, the script will produce models in every precision that is supported as a quantization output. Use this parameter to only produce models in a specific precision.                                                                                                                                        | ``omz_quantizer --all --dataset_dir <DATASET_DIR> --precisions=FP16-INT8``             |
+---------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------+
| ``--target_device``       | It's possible to specify a target device for Post-Training Optimization Toolkitto optimize for. The supported values are those accepted by the "target\_device" option in Post-Training Optimization Toolkit's config files. If this option is unspecified, Post-Training Optimization Toolkit's default is used.   | ``omz_quantizer --all --dataset_dir <DATASET_DIR> --target_device VPU``               |
+---------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------+
| ``--dry_run``             | The script can print the quantization commands without actually running them. With this option specified, the configuration file for Post-Training Optimization Toolkit will still be created, so that you can inspect it.                                                                                          | ``omz_quantizer --all --dataset_dir <DATASET_DIR> --dry_run``                          |
+---------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------+
| ``-p``/``--python``       | By default, the script will run Model Optimizer using the same Python executable that was used to run the script itself. Apply this parameter to use a different Python executable.                                                                                                                                 | ``omz_quantizer --all --dataset_dir <DATASET_DIR> --python my/python``                 |
+---------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------+
```-->
<p>该脚本将尝试使用多种方法找到训练后优化工具套件：</p>
<ol class="arabic">
<li><p>如果指定了 <code class="docutils literal notranslate"><span class="pre">--pot</span></code> 选项，那么它的值将被用作要运行的脚本的路径：</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>omz_quantizer --all --dataset_dir &lt;DATASET_DIR&gt; --pot my/openvino/path/post_training_optimization_toolkit/main.py
</pre></div>
</div>
</li>
<li><p>否则，如果选定的 Python 可执行文件可以找到 <code class="docutils literal notranslate"><span class="pre">pot</span></code> 切入点，则会使用该切入点。</p></li>
<li><p>否则，如果已执行 OpenVINO™ 工具套件的 <code class="docutils literal notranslate"><span class="pre">setupvars.sh</span></code>/<code class="docutils literal notranslate"><span class="pre">setupvars.bat</span></code> 脚本，则会将该脚本设置的环境变量用于在 OpenVINO™ 工具套件内查找训练后优化工具套件。</p></li>
<li><p>否则，脚本将失败。</p></li>
</ol>
</section>
<section id="id8">
<h2>模型信息转储器用法<a class="headerlink" href="#id8" title="永久链接至标题">¶</a></h2>
<p>基本用法是像以下方式运行脚本：</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>omz_info_dumper --all
</pre></div>
</div>
<p>脚本接受的其他选项如“共享选项”一节所述。</p>
<p>这将打印到所有模型的标准输出信息。该脚本的输出是一个 JSON 数组，其中的每个元素都是一个描述单个模型的 JSON 对象。每个这样的对象都有以下键：</p>
<!--
```{eval-rst}

+--------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Parameter                            | Explanation                                                                                                                                                                                                                                                                         |
+======================================+=====================================================================================================================================================================================================================================================================================+
| ``name``                             | The identifier of the model, as accepted by the ``--name`` option.                                                                                                                                                                                                                  |
+--------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| ``composite_model_name``             | The identifier of the composite model name, if the model is a part of composition of several models (e.g. encoder-decoder), otherwise - ``null``                                                                                                                                    |
+--------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| ``description``                      | Text describing the model. Paragraphs are separated by line feed characters.                                                                                                                                                                                                        |
+--------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| ``framework``                        | A string identifying the framework whose format the model is downloaded in. Current possible values are ``dldt`` (Inference Engine IR), ``caffe``, ``mxnet``, ``onnx``, ``pytorch`` and ``tf`` (TensorFlow). Additional possible values might be added in the future.               |
+--------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| ``license_url``                      | A URL for the license that the model is distributed under.                                                                                                                                                                                                                          |
+--------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| ``accuracy_config``                      | Path to the model accuracy config in the user's file system.                                                                                                                                                                                                                          |
+--------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| ``model_config``                      | Path to the model configuration file in the user's file system.                                                                                                                                                                                                                          |
+--------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| ``precisions``                       | The list of precisions that the model has IR files for. For models downloaded in a format other than the Inference Engine IR format, these are the precisions that the model converter can produce IR files in. Current possible values are:                                        |
|                                      | * `FP16`                                                                                                                                                                                                                                                                            |
|                                      | * `FP16-INT1`                                                                                                                                                                                                                                                                       |
|                                      | * `FP16-INT8`                                                                                                                                                                                                                                                                       |
|                                      | * `FP32`                                                                                                                                                                                                                                                                            |
|                                      | * `FP32-INT1`                                                                                                                                                                                                                                                                       |
|                                      | * `FP32-INT8`                                                                                                                                                                                                                                                                       |
+--------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| ``quantization_output_precisions``   | The list of precisions that the model can be quantized to by the model quantizer. Current possible values are ``FP16-INT8`` and ``FP32-INT8``; additional possible values might be added in the future.                                                                             |
+--------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| ``subdirectory``                     | The subdirectory of the output tree into which the downloaded or converted files will be placed by the downloader or the converter, respectively.                                                                                                                                   |
+--------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| ``task_type``                        | a string identifying the type of task that the model performs. Current possible values are:                                                                                                                                                                                         |
|                                      |                                                                                                                                                                                                                                                                                     |
|                                      | * `action_recognition`                                                                                                                                                                                                                                                              |
|                                      | * `classification`                                                                                                                                                                                                                                                                  |
|                                      | * `colorization`                                                                                                                                                                                                                                                                    |
|                                      | * `detection`                                                                                                                                                                                                                                                                       |
|                                      | * `face_recognition`                                                                                                                                                                                                                                                                |
|                                      | * `feature_extraction`                                                                                                                                                                                                                                                              |
|                                      | * `head_pose_estimation`                                                                                                                                                                                                                                                            |
|                                      | * `human_pose_estimation`                                                                                                                                                                                                                                                           |
|                                      | * `image_inpainting`                                                                                                                                                                                                                                                                |
|                                      | * `image_processing`                                                                                                                                                                                                                                                                |
|                                      | * `image_translation`                                                                                                                                                                                                                                                               |
|                                      | * `instance_segmentation`                                                                                                                                                                                                                                                           |
|                                      | * `machine_translation`                                                                                                                                                                                                                                                             |
|                                      | * `monocular_depth_estimation`                                                                                                                                                                                                                                                      |
|                                      | * `named_entity_recognition`                                                                                                                                                                                                                                                        |
|                                      | * `noise_suppression`                                                                                                                                                                                                                                                               |
|                                      | * `object_attributes`                                                                                                                                                                                                                                                               |
|                                      | * `optical_character_recognition`                                                                                                                                                                                                                                                   |
|                                      | * `place_recognition`                                                                                                                                                                                                                                                               |
|                                      | * `question_answering`                                                                                                                                                                                                                                                              |
|                                      | * `salient_object_detection`                                                                                                                                                                                                                                                        |
|                                      | * `semantic_segmentation`                                                                                                                                                                                                                                                           |
|                                      | * `sound_classification`                                                                                                                                                                                                                                                            |
|                                      | * `speech_recognition`                                                                                                                                                                                                                                                              |
|                                      | * `style_transfer`                                                                                                                                                                                                                                                                  |
|                                      | * `text_prediction`                                                                                                                                                                                                                                                                 |
|                                      | * `text_to_speech`                                                                                                                                                                                                                                                                  |
|                                      | * `time_series`                                                                                                                                                                                                                                                                     |
|                                      | * `token_recognition`                                                                                                                                                                                                                                                               |
+--------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| ``input_info``                       | The list of inputs containing the information about input name, shape and layout.                                                                                                                                                                                                   |
+--------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
+--------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| ``model_stages``                     | The list of model stages, in case if the model is a composition of several models,  otherwise the list is empty                                                                                                                                                                     |
+--------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
+--------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
```-->
</section>
<section id="id9">
<h2>共享选项<a class="headerlink" href="#id9" title="永久链接至标题">¶</a></h2>
<p>这是所有工具都接受的某些选项。</p>
<p><code class="docutils literal notranslate"><span class="pre">-h</span></code>/<code class="docutils literal notranslate"><span class="pre">--help</span></code> 可以用于打印帮助消息：</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>omz_TOOL --help
</pre></div>
</div>
<p>有几个相互排斥的筛选选项可以选择工具将处理的模型：</p>
<!--
```{eval-rst}

+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------+
| Parameter    | Explanation                                                                                                                                                                                                                                                                       | Example                                   |
+==============+===================================================================================================================================================================================================================================================================================+===========================================+
| ``--all``    | Selects all models                                                                                                                                                                                                                                                                | ``omz_TOOL --all``                        |
+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------+
| ``--name``   | takes a comma-separated list of patterns and selects models that match at least one of these patterns. The patterns may contain shell-style wildcards. See https://docs.python.org/3/library/fnmatch.html for a full description of the pattern syntax. For composite models, the name of composite model is accepted, as well as the names of individual models it consists of.   | ``omz_TOOL --name 'mtcnn,densenet-*'``    |
+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------+
| ``--list``   | takes a path to a file that must contain a list of patterns and selects models that match at least one of those patterns. For composite models, the name of composite model is accepted, as well as the names of individual models it consists of                                 | ``omz_TOOL --list my.lst``                |
+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------+
```-->
<p>如需查看可用模型，可以使用 <code class="docutils literal notranslate"><span class="pre">--print_all</span></code> 选项。指定此选项后，该工具将打印配置文件中定义的所有模型名称并退出：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ omz_TOOL --print_all
action-recognition-0001-decoder
action-recognition-0001-encoder
age-gender-recognition-retail-0013
driver-action-recognition-adas-0002-decoder
driver-action-recognition-adas-0002-encoder
emotions-recognition-retail-0003
face-detection-adas-0001
face-detection-retail-0004
face-detection-retail-0005
[...]
</pre></div>
</div>
<p>必须指定 <code class="docutils literal notranslate"><span class="pre">--print_all</span></code> 或其中一个筛选选项。</p>
</section>
<section id="id10">
<h2>数据集的数据下载程序用法<a class="headerlink" href="#id10" title="永久链接至标题">¶</a></h2>
<p>用法是按如下所示运行脚本：</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>omz_data_downloader -o my/output/directory
</pre></div>
</div>
<p>这会将数据集的数据从安装位置复制到指定位置。
如果未设置 <code class="docutils literal notranslate"><span class="pre">-o</span></code>/<code class="docutils literal notranslate"><span class="pre">--output_dir</span></code> 选项，则会将文件复制到以当前目录为根的目录树中。</p>
<hr class="docutils" />
<p>OpenVINO 是英特尔公司或其子公司在美国和/或其他国家的商标。</p>
<p>版权所有 © 2018-2019，英特尔公司</p>
<p>根据 Apache 许可证，版本 2.0（“许可证”）获得许可；除非遵守许可证，否则您不得使用此文件。
您可以在以下位置获得一份许可证：</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span> http://www.apache.org/licenses/LICENSE-2.0
</pre></div>
</div>
<p>除非适用法律要求或书面同意，否则根据许可证分发的软件是按“原样”分发，没有任何类型明示或暗示的保证或条件。
请参阅许可证，了解许可证下适用于权限和限制的特定语言。</p>
</section>
</section>


                </div>
            
            
                <div class='prev-next-bottom'>
                  
    <a class='button bttn-sec button-size-l' id="prev-link" href="OTE_landing_page.html" title="previous page">Prev</a>
    <a class='button bttn-sec button-size-l' id="next-link" href="common_inference_pipeline.html" title="next page">Next</a>

                </div>
            
          </main>
          

      </div>
    </div>
  
  <script src="_static/js/index.be7d3bbb2ef33a8344ce.js"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2022, Various.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.2.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>